{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srijit43/NLP-theory-and-code/blob/main/05_11_BestDR_vs_BestGB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v63wLnDErz4"
      },
      "source": [
        "# Building Machine Learning Classifiers: Model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS8NtrxRErz7"
      },
      "source": [
        "### Read in & clean text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1rxC2x4Erz8",
        "outputId": "44893462-ef90-4db2-ce13-4721416f30c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
        "data.columns = ['label', 'body_text']\n",
        "\n",
        "def count_punct(text):\n",
        "    count = sum([1 for char in text if char in string.punctuation])\n",
        "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
        "\n",
        "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
        "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "    tokens = re.split('\\W+', text)\n",
        "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_ooAjUXErz-"
      },
      "source": [
        "### Split into train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "P2H9LRmkErz_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[['body_text', 'body_len', 'punct%']], data['label'], test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdgoQ_ASErz_"
      },
      "source": [
        "### Vectorize text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "shipRGQyErz_"
      },
      "outputs": [],
      "source": [
        "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
        "tfidf_vect_fit = tfidf_vect.fit(X_train['body_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Adjustment"
      ],
      "metadata": {
        "id": "StM9WpqvJEE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tfidf_vect_fit = tfidf_vect_fit.rename(str,axis='columns')\n",
        "\n",
        "\n",
        "tfidf_train = tfidf_vect_fit.transform(X_train['body_text'])  #will have same cols as test and train as it was fitted on train data only recognizes that\n",
        "tfidf_test = tfidf_vect_fit.transform(X_test['body_text'])\n",
        "\n",
        "X_train_vect = pd.concat([X_train[['body_len','punct%']].reset_index(drop=True),pd.DataFrame(tfidf_train.toarray())],axis=1)\n",
        "X_test_vect =  pd.concat([X_test[['body_len','punct%']].reset_index(drop=True),pd.DataFrame(tfidf_test.toarray())],axis=1)\n",
        "\n",
        "X_train_vect = X_train_vect.rename(str,axis=1)\n",
        "X_test_vect = X_test_vect.rename(str,axis=1)\n",
        "#y_train = y_train.rename(str,axis=1)\n",
        "#y_test = y_test.rename(str,axis=1)"
      ],
      "metadata": {
        "id": "ThM5am1gJF7o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_vect.head())\n",
        "print(X_test_vect.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDDcgPb_LRFn",
        "outputId": "f7e4d5a5-b6a5-460d-cec2-355d47e6e7ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   body_len  punct%    0    1    2    3    4    5    6    7  ...  7113  7114  \\\n",
            "0        37     5.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "1       128     4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "2        62     8.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "3        45    11.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "4       120     4.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "\n",
            "   7115  7116  7117  7118  7119  7120  7121  7122  \n",
            "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "\n",
            "[5 rows x 7125 columns]\n",
            "   body_len  punct%    0    1    2    3    4    5    6    7  ...  7113  7114  \\\n",
            "0        40     2.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "1        16    12.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "2        41     4.9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "3       128     5.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "4        60     3.3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "\n",
            "   7115  7116  7117  7118  7119  7120      7121  7122  \n",
            "0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  \n",
            "1   0.0   0.0   0.0   0.0   0.0   0.0  0.469117   0.0  \n",
            "2   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  \n",
            "3   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  \n",
            "4   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  \n",
            "\n",
            "[5 rows x 7125 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdjn9JEOEr0A"
      },
      "source": [
        "### Final evaluation of models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "yNGprbFhEr0A"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSNgN80-Er0B",
        "outputId": "cb3f9542-9c57-4cf6-a787-2a8c28ad062a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time:11.145 , Predict time:0.194 , Precision: 1.0 / Recall: 0.794 / Accuracy: 0.974\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
        "\n",
        "start = time.time()   #start time\n",
        "\n",
        "rf_model = rf.fit(X_train_vect, y_train)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "fit_time = (end - start) #fit time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "y_pred = rf_model.predict(X_test_vect)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "pred_time = (end - start)\n",
        "\n",
        "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
        "print('Fit time:{} , Predict time:{} , Precision: {} / Recall: {} / Accuracy: {}'.format(round(fit_time,3),round(pred_time,3),\n",
        "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNodupdBEr0B",
        "outputId": "43744082-b765-404b-ddc2-d575058c37c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time:213.341, Pred_time:0.131, Precision: 0.951 / Recall: 0.83 / Accuracy: 0.973\n"
          ]
        }
      ],
      "source": [
        "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
        "\n",
        "start = time.time()\n",
        "gb_model = gb.fit(X_train_vect, y_train)\n",
        "end = time.time()\n",
        "fit_time = (end - start)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "y_pred = gb_model.predict(X_test_vect)\n",
        "end = time.time()\n",
        "pred_time = (end - start)\n",
        "\n",
        "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
        "print('Fit time:{}, Pred_time:{}, Precision: {} / Recall: {} / Accuracy: {}'.format(round(fit_time,3),round(pred_time,3),\n",
        "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLAUDgOcN5OX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}